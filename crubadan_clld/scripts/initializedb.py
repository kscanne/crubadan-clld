# -*- coding: utf-8 -*-

from __future__ import unicode_literals
import sys

from clld.scripts.util import initializedb, Data
from clld.db.meta import DBSession
from clld.db.models import common

import crubadan_clld
from crubadan_clld import models

import os
import sys
import codecs
from path import Path

from coords import coords


rootDataDir = '/data/crubadan'
rootClldDir = '/data/crubadan-clld'


def prepSysDirs():
    if (not os.path.isdir(rootClldDir)):
        print "You must create " + rootClldDir + " before building the database."
        sys.exit(1)
    if (os.path.exists(rootClldDir + '/clld-db.sqlite')):
        print "Replacing previous clld-db.sqlite"
        os.remove(rootClldDir + '/clld-db.sqlite')



def fillTable(dbsession):
    langs = os.listdir(rootDataDir)
    c = 1
    for lang in langs:
        fname = rootDataDir + '/' + lang + '/' + 'EOLAS'
        mname = rootClldDir + '/metadata/' + lang + '.txt'
        trigfname = rootDataDir + '/' + lang + '/' + 'SAMPSENTS'
        if (os.path.isfile(fname)):
            f = codecs.open(fname, encoding='utf-8')
            fm = codecs.open(mname, encoding='utf-8')
            t = codecs.open(trigfname, encoding='utf-8')
            dic = {}

            # Read all ordinary data fields
            for line in f:
                parseAdd(line,dic,'')

            # Read all codata fields generated by that other script
            for line in fm:
                parseAdd(line,dic,'m_')

            # Assign lat/long IF they can be found
            if dic[u'country'] in coords:
                (lati,longi) = coords[dic[u'country']]
            else:
                (lati,longi) = (None,None)

            # Fill the database model
            ws = models.WritingSystem(

                # System stuff
                id = lang,
                jsondata = dic,
                name = dic[u'name_english'],
                description = dic[u'classification'],

                # For the maps
                latitude = lati,
                longitude = longi,

                # Main data file
                eng_name = dic[u'name_english'],
                native_name = dic[u'name_native'],
                bcp47 = lang,
                iso6393 = dic[u'ISO_639-3'],
                country = dic[u'country'],
                script = dic[u'script'],
                parent_ws = dic[u'parent'],
                child_ws = dic[u'children'],
                ling_classification = dic[u'classification'],
                ethnologue_name = dic[u'ethnologue'],
                glottolog_name = dic[u'glottolog'],
            )

            # Add it to the database
            dbsession.add(ws)

            # Let the user know it's working
            print 'Added ' + lang + ' ...'
            c += 1

def parseAdd(line,dic,prefix):
    if (line[0] != u'#'):
        (key,d,value) = line.partition(u' ')
        p_key = prefix + key
        if (value == u"XXX\n"):
            dic[p_key] = u"(Unknown)\n"
        elif ((value == u"none\n") or (value == u"\n")):
            dic[p_key] = u"None\n"
        else:
            dic[p_key] = value

def main(args):
    data = Data()

    dataset = common.Dataset(
        id= u'An Crúbadán',
        name= u'An Crúbadán',
        publisher_name="Saint Louis University",
        publisher_place="Saint Louis, USA",
        publisher_url="http://www.slu.edu/",
        description="Linguistic datasets for over 2000 languages created from web-crawled text corpora",
        contact="kscanne@gmail.com",
        license='http://creativecommons.org/licenses/by/4.0/',
        jsondata={
            'license_icon': 'https://licensebuttons.net/l/by/4.0/88x31.png',
            'license_name': 'Creative Commons Attribution 4.0 International License',
            },
        domain='crubadan.org',
        )

    DBSession.add(dataset)
    DBSession.flush()

    editor = data.add(common.Contributor, "Kevin Scannell", id="Kevin Scannell", name="Kevin Scannell", email="kscanne@gmail.com")
    common.Editor(dataset=dataset, contributor=editor, ord=0)
    DBSession.flush()

    fillTable(DBSession)

def prime_cache(args):
    """If data needs to be denormalized for lookup, do that here.
    This procedure should be separate from the db initialization, because
    it will have to be run periodiucally whenever data has been updated.
    """


if __name__ == '__main__':
    prepSysDirs()
    initializedb(create=main, prime_cache=prime_cache)
    sys.exit(0)
